{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import sklearn.manifold as manifold\n",
    "from numpy import genfromtxt\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.manifold import LocallyLinearEmbedding\n",
    "from sklearn.manifold import SpectralEmbedding\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def give_me_some_data(path_to_file, headers = None, separator = ',',float_precision = None):\n",
    "    if(path_to_file):\n",
    "        return pd.read_csv(\n",
    "            filepath_or_buffer=path_to_file, \n",
    "            header=headers, \n",
    "            sep=separator,\n",
    "            float_precision=float_precision\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def give_me_a_dr(dr_tech = \"PCA\", n_components = 150, n_neighbours = 150):\n",
    "    switcher = {\n",
    "        \"PCA\" : PCA(n_components=n_components),\n",
    "        \"TruncatedSVD\": TruncatedSVD(n_components=n_components),\n",
    "        \"LLE-Standard\": LocallyLinearEmbedding(n_neighbors=n_neighbours,\n",
    "                                             n_components=n_components, method = 'standard'),\n",
    "        \"LLE-Hessian\": LocallyLinearEmbedding(n_neighbors=n_neighbours,\n",
    "                                             n_components=n_components, method = 'hessian'),\n",
    "        \"spectral_embedding\": SpectralEmbedding(n_components=n_components, random_state=0,\n",
    "                                      eigen_solver=\"arpack\"),\n",
    "        \"tsne\": TSNE(n_components=n_components, init='pca', random_state=0)\n",
    "    }\n",
    "    return switcher[dr_tech]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def give_me_a_classifier(classifier = \"SVC\", neighbours = None):\n",
    "    switcher = {\n",
    "        \"SVC\": SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
    "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
    "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
    "  tol=0.001, verbose=False),\n",
    "        \"SGD\": SGDClassifier(random_state=42, max_iter=1000, tol=1e-3),\n",
    "        \"KNN\": KNeighborsClassifier(n_neighbors=neighbours)\n",
    "    }\n",
    "    return switcher[classifier]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def give_me_a_pipeline(dr = None, classifier = None):\n",
    "    return  Pipeline(steps=[(\"DR\", dr), ('classify', classifier)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the dataset\n",
    "training_data = give_me_some_data(\n",
    "    path_to_file='../data/train.dat', \n",
    "    headers=None, \n",
    "    separator=' ',\n",
    "    float_precision='high'\n",
    ")\n",
    "\n",
    "training_labels = give_me_some_data(\n",
    "    path_to_file='../data/train.labels', \n",
    "    headers=None, \n",
    ")\n",
    "\n",
    "test_data = give_me_some_data(\n",
    "    path_to_file='../data/test.dat', \n",
    "    headers=None, \n",
    "    separator=' ',\n",
    "    float_precision='high' \n",
    ")\n",
    "\n",
    "# test_data\n",
    "\n",
    "# df.to_csv(\"../data/aaj.csv\", sep='\\t', encoding='utf-8')\n",
    "# df.nunique().to_csv(\"../data/unique_vals.csv\", sep='\\t', encoding='utf-8')\n",
    "# cols = df.columns\n",
    "# for col in cols:\n",
    "#     df[col] = df[col].astype(float) \n",
    "# print(df)\n",
    "\n",
    "# extract the vectors from the Pandas data file\n",
    "# X = df.iloc[:,1:].values\n",
    "# df\n",
    "# my_data = np.loadtxt('../data/train.dat', delimiter=' ',dtype = np.float64)\n",
    "# np.set_printoptions(precision = 20)\n",
    "# my_data\n",
    "# df1 = pd.DataFrame(my_data)\n",
    "# df1\n",
    "\n",
    "# standardise the data\n",
    "# X_std = StandardScaler().fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    training_data,\n",
    "    training_labels,\n",
    "    test_size=0.2,\n",
    "    shuffle=True,\n",
    "    random_state=42,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.60      0.80      0.68      2116\n",
      "          2       0.45      0.43      0.44      1500\n",
      "          3       0.00      0.00      0.00       362\n",
      "          4       0.00      0.00      0.00        58\n",
      "          5       0.00      0.00      0.00        41\n",
      "          6       0.00      0.00      0.00         4\n",
      "          7       0.00      0.00      0.00         2\n",
      "          8       0.00      0.00      0.00       153\n",
      "         10       0.00      0.00      0.00         1\n",
      "         11       0.00      0.00      0.00         1\n",
      "\n",
      "avg / total       0.46      0.55      0.50      4238\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sudhani/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# for k, v in dict.items():\n",
    "#     print(k,v)\n",
    "# compute_pipeline = give_me_a_pipeline(give_me_a_dr(dr_tech=\"PCA\"),give_me_a_classifier(classifier=\"SVC\"))\n",
    "# compute_pipeline.fit(X_train, y_train)\n",
    "# y_pred = compute_pipeline.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Computing LLE embedding\")\n",
    "# X_r, err = manifold.locally_linear_embedding(training_data, n_neighbors=5000,\n",
    "#                                              n_components=50, method = 'hessian')\n",
    "# print(\"Done. Reconstruction error: %g\" % err)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dasdasdasdasd"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
